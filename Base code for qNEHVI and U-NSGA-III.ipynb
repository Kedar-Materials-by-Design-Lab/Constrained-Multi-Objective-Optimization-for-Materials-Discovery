{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "###########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# utilities\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from botorch.utils.multi_objective.hypervolume import infer_reference_point\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "###########\n",
    "\n",
    "# pymoo dependencies\n",
    "import pymoo\n",
    "\n",
    "from pymoo.factory import get_problem\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.algorithms.moo.unsga3 import UNSGA3\n",
    "from pymoo.algorithms.moo.ctaea import CTAEA\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation, get_reference_directions, get_termination\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.util.termination.no_termination import NoTermination\n",
    "from pymoo.core.evaluator import set_cv\n",
    "from pymoo.factory import get_performance_indicator\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this is for the colorbar, you can change the cmap if you prefer other colour schemes\n",
    "from matplotlib.cm import ScalarMappable\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "\n",
    "# function to return the std dev across runs\n",
    "def ci(y, N_TRIALS):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, WhiteKernel\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qnehvi(problem, ref_point, initial_x, # must haves\n",
    "                    N_BATCH, BATCH_SIZE, \n",
    "                    random_state=torch.randint(1000000, (1,)).item(), noise=0, verbose=False): # change noise here!\n",
    "    \n",
    "    print(\"Optimizing with qNEHVI\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # some initializing \n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "    train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # normalize inputs to [0,1] first before feeding into model\n",
    "    standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "    standard_bounds[1] = 1\n",
    "    train_x_gp = normalize(train_x, standard_bounds)\n",
    "    \n",
    "    # form the output train_y data by concentenating ground truth train_obj with its feasibility value on the rightmost\n",
    "    # this is necessary since the surrogate GpyTorch model needs to model BOTH obj and con for predicted candidates\n",
    "    train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "    # define and train surrogate models for objective and constraint\n",
    "    models = []\n",
    "    for i in range(train_y.shape[-1]):\n",
    "        models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "    ##########    \n",
    "    \n",
    "    def create_idxr(i):\n",
    "        def idxr(Z):\n",
    "            return Z[..., i]\n",
    "\n",
    "        return idxr\n",
    "\n",
    "    def create_idxrs():\n",
    "        return [create_idxr(i=i) for i in range(problem.n_obj, problem.n_obj+problem.n_constr)]\n",
    "    \n",
    "    # original location for an extra HV check wrt to initial samples\n",
    "    \n",
    "    ########## ########## ########## start of iteration loop\n",
    "\n",
    "\n",
    "    # training loop for N_BATCH iterations\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        t3 = time.time()\n",
    "                \n",
    "        # fit the surrogate model\n",
    "        fit_gpytorch_model(mll)    \n",
    "                \n",
    "        ##########\n",
    "            \n",
    "        # define the acqusition function for EIC if feas_weighting is false\n",
    "        acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "            X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "            sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "            objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "            constraints=create_idxrs(), # constraint on last n_constr col\n",
    "            prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # propose candidates given defined qNEHVI acq func given model and latest observed training data\n",
    "        new_x, _ = optimize_acqf(\n",
    "                        acq_function=acq_func,\n",
    "                        bounds=standard_bounds, # since train_x was normalized\n",
    "                        q=BATCH_SIZE, # no of candidates to propose in parallel\n",
    "                        num_restarts=2, # no of restarts if q candidates fail to show improvement\n",
    "                        raw_samples=128,  # pool of samples to choose the starting points from\n",
    "                        options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                        )\n",
    "\n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "\n",
    "        # feed new proposed observations into objective func to get its new ground truth\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "        # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "        new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "        new_con_noisy = new_con + noise*torch.randn_like(new_con)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "        train_con_noisy = torch.cat([train_con_noisy, new_con_noisy])\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # computing HV of current candidate list\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "        \n",
    "        hvs.append(volume)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        # update the surrogate models for next iteration\n",
    "        train_x_gp = normalize(train_x, standard_bounds) # dont forget to renormalize!\n",
    "        train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "        models = []\n",
    "        for i in range(train_y.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model = ModelListGP(*models)\n",
    "        mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "            \n",
    "        del new_x, new_obj, new_con, new_obj_noisy, new_con_noisy, train_x_gp, train_y\n",
    "        torch.cuda.empty_cache() # clear some memory here between each run/trial     \n",
    "        \n",
    "        ########## ########## ########## end of iteration loop\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")       \n",
    "    \n",
    "    # returns the HV score across iterations, total training set as an array\n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy()\n",
    "\n",
    "def optimize_nsga3(problem, ref_point, initial_x, # must haves\n",
    "                   N_BATCH, pop_size,\n",
    "                   ref_num=10, # as a rule of thumb, pop_size>ref_num,\n",
    "                   noise=0, random_state=np.random.randint(0, 1000000, (1,)).item(), verbose=False):\n",
    "    \n",
    "    print(\"Optimizing with NSGA-III\")\n",
    "    \n",
    "    t0 = time.time()    \n",
    "    \n",
    "    # some initializing\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    noise=noise\n",
    "\n",
    "    # define a pymoo problem class based on the torch class\n",
    "    class PymooProblem(ElementwiseProblem):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__(n_var=problem.n_var,\n",
    "                             n_obj=problem.n_obj,\n",
    "                             n_constr=problem.n_constr,\n",
    "                             xl=problem.bounds[0].cpu().numpy(),\n",
    "                             xu=problem.bounds[1].cpu().numpy())\n",
    "\n",
    "        def _evaluate(self, X, out, *args, **kwargs):\n",
    "            # base input/output from torch class\n",
    "            train_x = torch.tensor(X.tolist(), **tkwargs).unsqueeze(dim=0)\n",
    "            \n",
    "            # take the noisy observations for algo\n",
    "            train_obj, train_con = problem.evaluate(train_x)\n",
    "            train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "            train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "\n",
    "            # output the noisy observations instead\n",
    "            out[\"F\"] = -train_obj_noisy.cpu().numpy() # flip since botorch assumes maximisation vs pymoo minimization\n",
    "            out[\"G\"] = train_con_noisy.cpu().numpy()\n",
    "            \n",
    "    ##########        \n",
    "\n",
    "    pymooproblem = PymooProblem()\n",
    "\n",
    "    # create the reference directions to be used for the optimization\n",
    "    ref_dirs = get_reference_directions(\"energy\", problem.n_obj, ref_num, seed=random_state)\n",
    "    \n",
    "    # initial sampling\n",
    "    sampling = initial_x.cpu().numpy()\n",
    "    \n",
    "    # create the algorithm object\n",
    "    algorithm = UNSGA3(pop_size=pop_size,\n",
    "                      ref_dirs=ref_dirs,\n",
    "                      sampling=sampling\n",
    "                     )\n",
    "\n",
    "    # execute the optimization, take N_BATCH+1 since 1st iteration is just the initial sampling\n",
    "    res = minimize(pymooproblem, algorithm, seed=random_state, termination=('n_gen', N_BATCH+1),\n",
    "                   verbose=verbose, save_history=True)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")\n",
    "\n",
    "    ##########\n",
    "        \n",
    "    # convert population data into tensor form\n",
    "    # initial data\n",
    "    train_x = torch.tensor(res.history[0].pop.get(\"X\").tolist(), **tkwargs)\n",
    "    train_obj, train_con = problem.evaluate(train_x) \n",
    "    # population at each iteration\n",
    "    for i in range(1,N_BATCH+1): # don't forget we did +1 for total iterations\n",
    "        new_x = torch.tensor(res.history[i].pop.get(\"X\").tolist(), **tkwargs)\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "\n",
    "    ##########\n",
    "        \n",
    "    # calculate hypervolume based on checks, done on noiseless train_obj and train_con\n",
    "    iterdict = {}\n",
    "    a = 0\n",
    "    b = initial_x.shape[0]\n",
    "    for i in range(0, N_BATCH+1):\n",
    "\n",
    "        iterdict[i] = (a, b)\n",
    "        # a stays at zero\n",
    "        b+=pop_size\n",
    "    \n",
    "    for i in range(0,N_BATCH):\n",
    "        hvs_obj = train_obj[iterdict[i][0]:iterdict[i][1]]\n",
    "        hvs_con = train_con[iterdict[i][0]:iterdict[i][1]]\n",
    "\n",
    "        is_feas = (hvs_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = hvs_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "        \n",
    "        hvs.append(volume)\n",
    "        \n",
    "    print(\"DONE!\\n\")\n",
    "        \n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy()\n",
    "\n",
    "def optimize_qnehvi_noconstr(problem, ref_point, initial_x, # must haves\n",
    "                    N_BATCH, BATCH_SIZE, \n",
    "                    random_state=torch.randint(1000000, (1,)).item(), noise=0, verbose=False): # change noise here!\n",
    "    \n",
    "    print(\"Optimizing with qNEHVI\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # some initializing \n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj = problem.evaluate(train_x)\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # normalize inputs to [0,1] first before feeding into model\n",
    "    standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "    standard_bounds[1] = 1\n",
    "    train_x_gp = normalize(train_x, standard_bounds)\n",
    "    \n",
    "    # form the output train_y data by concentenating ground truth train_obj with its feasibility value on the rightmost\n",
    "    # this is necessary since the surrogate GpyTorch model needs to model BOTH obj and con for predicted candidates\n",
    "    train_y = train_obj_noisy\n",
    "\n",
    "    # define and train surrogate models for objective and constraint\n",
    "    models = []\n",
    "    for i in range(train_y.shape[-1]):\n",
    "        models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "    ##########    \n",
    "    \n",
    "    # original location for an extra HV check wrt to initial samples\n",
    "    \n",
    "    ########## ########## ########## start of iteration loop\n",
    "\n",
    "\n",
    "    # training loop for N_BATCH iterations\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        t3 = time.time()\n",
    "                \n",
    "        # fit the surrogate model\n",
    "        fit_gpytorch_model(mll)    \n",
    "                \n",
    "        ##########\n",
    "            \n",
    "        # define the acqusition function for EIC if feas_weighting is false\n",
    "        acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "            X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "            sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "            objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "            prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # propose candidates given defined qNEHVI acq func given model and latest observed training data\n",
    "        new_x, _ = optimize_acqf(\n",
    "                        acq_function=acq_func,\n",
    "                        bounds=standard_bounds, # since train_x was normalized\n",
    "                        q=BATCH_SIZE, # no of candidates to propose in parallel\n",
    "                        num_restarts=2, # no of restarts if q candidates fail to show improvement\n",
    "                        raw_samples=128,  # pool of samples to choose the starting points from\n",
    "                        options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                        )\n",
    "\n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "\n",
    "        # feed new proposed observations into objective func to get its new ground truth\n",
    "        new_obj = problem.evaluate(new_x)\n",
    "\n",
    "        # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "        new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # computing HV of current candidate list\n",
    "        pareto_mask = is_non_dominated(train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "        pareto_y = train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "        volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        \n",
    "        hvs.append(volume)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        # update the surrogate models for next iteration\n",
    "        train_x_gp = normalize(train_x, standard_bounds) # dont forget to renormalize!\n",
    "        train_y = train_obj_noisy\n",
    "\n",
    "        models = []\n",
    "        for i in range(train_y.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model = ModelListGP(*models)\n",
    "        mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "            \n",
    "        del new_x, new_obj, new_obj_noisy, train_x_gp, train_y\n",
    "        torch.cuda.empty_cache() # clear some memory here between each run/trial     \n",
    "        \n",
    "        ########## ########## ########## end of iteration loop\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")       \n",
    "    \n",
    "    # returns the HV score across iterations, total training set as an array\n",
    "    return hvs, torch.hstack([train_x, train_obj]).cpu().numpy()\n",
    "\n",
    "def optimize_nsga3_noconstr(problem, ref_point,  initial_x, # must haves\n",
    "                            N_BATCH, pop_size,\n",
    "                            ref_num=10, # as a rule of thumb, pop_size>ref_num,\n",
    "                            noise=0, random_state=np.random.randint(0, 1000000, (1,)).item(), verbose=False):\n",
    "    \n",
    "    print(\"Optimizing with NSGA-III\")\n",
    "    \n",
    "    t0 = time.time()    \n",
    "    \n",
    "    # some initializing\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    noise=noise\n",
    "\n",
    "    # define a pymoo problem class based on the torch class\n",
    "    class PymooProblem(ElementwiseProblem):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__(n_var=problem.n_var,\n",
    "                             n_obj=problem.n_obj,\n",
    "                             xl=problem.bounds[0].cpu().numpy(),\n",
    "                             xu=problem.bounds[1].cpu().numpy())\n",
    "\n",
    "        def _evaluate(self, X, out, *args, **kwargs):\n",
    "            # base input/output from torch class\n",
    "            train_x = torch.tensor(X.tolist(), **tkwargs).unsqueeze(dim=0)\n",
    "            \n",
    "            # take the noisy observations for algo\n",
    "            train_obj = problem.evaluate(train_x)\n",
    "            train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "\n",
    "            # output the noisy observations instead\n",
    "            out[\"F\"] = -train_obj_noisy.cpu().numpy() # flip since botorch assumes maximisation vs pymoo minimization\n",
    "            \n",
    "    ##########        \n",
    "\n",
    "    pymooproblem = PymooProblem()\n",
    "\n",
    "    # create the reference directions to be used for the optimization\n",
    "    ref_dirs = get_reference_directions(\"energy\", problem.n_obj, ref_num, seed=random_state)\n",
    "    \n",
    "    # initial sampling\n",
    "    sampling = initial_x.cpu().numpy()\n",
    "    \n",
    "    # create the algorithm object\n",
    "    algorithm = UNSGA3(pop_size=pop_size,\n",
    "                      ref_dirs=ref_dirs,\n",
    "                      sampling=sampling\n",
    "                     )\n",
    "\n",
    "    # execute the optimization, take N_BATCH+1 since 1st iteration is just the initial sampling\n",
    "    res = minimize(pymooproblem, algorithm, seed=random_state, termination=('n_gen', N_BATCH+1),\n",
    "                   verbose=verbose, save_history=True)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # convert population data into tensor form\n",
    "    # initial data\n",
    "    train_x = torch.tensor(res.history[0].pop.get(\"X\").tolist(), **tkwargs)\n",
    "    train_obj = problem.evaluate(train_x) \n",
    "    # population at each iteration\n",
    "    for i in range(1,N_BATCH+1): # don't forget we did +1 for total iterations\n",
    "        new_x = torch.tensor(res.history[i].pop.get(\"X\").tolist(), **tkwargs)\n",
    "        new_obj = problem.evaluate(new_x)\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        \n",
    "    ##########\n",
    "    \n",
    "    # calculate hypervolume based on checks, done on noiseless train_obj and train_con\n",
    "    iterdict = {}\n",
    "    a = 0\n",
    "    b = initial_x.shape[0]\n",
    "    for i in range(0, N_BATCH+1):\n",
    "\n",
    "        iterdict[i] = (a, b)\n",
    "        # a stays at zero\n",
    "        b+=pop_size\n",
    "    \n",
    "    for i in range(0,N_BATCH):\n",
    "        hvs_obj = train_obj[iterdict[i][0]:iterdict[i][1]]\n",
    "\n",
    "        # computing HV of current candidate list\n",
    "        pareto_mask = is_non_dominated(hvs_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "        pareto_y = hvs_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "        volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "                \n",
    "        hvs.append(volume)   \n",
    "        \n",
    "    ##########\n",
    "     \n",
    "    return hvs, torch.hstack([train_x, train_obj]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 8\n",
    "\n",
    "from botorch.test_functions.multi_objective import ZDT1\n",
    "\n",
    "ZDT1base = ZDT1(dim=dimensions, negate=True).to(**tkwargs)\n",
    "\n",
    "class Problem_ZDT1(torch.nn.Module):\n",
    "    n_var = dimensions\n",
    "    n_obj = 2\n",
    "    n_constr = 1 # inequality constraints only!\n",
    "        \n",
    "    bounds = torch.vstack([torch.zeros(dimensions, **tkwargs),torch.ones(dimensions, **tkwargs)])\n",
    "    \n",
    "    def evaluate(X):        \n",
    "    \n",
    "        output = ZDT1base(X)\n",
    "        \n",
    "        # for 1 constraint, take c1.unsqueeze(dim=-1)\n",
    "        # for >1 constraint, take torch.stack([c1, c2....], dim=-1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "from botorch.test_functions.multi_objective import ZDT2\n",
    "\n",
    "ZDT2base = ZDT2(dim=dimensions, negate=True).to(**tkwargs)\n",
    "\n",
    "class Problem_ZDT2(torch.nn.Module):\n",
    "    n_var = dimensions\n",
    "    n_obj = 2\n",
    "    n_constr = 1 # inequality constraints only!\n",
    "        \n",
    "    bounds = torch.vstack([torch.zeros(dimensions, **tkwargs),torch.ones(dimensions, **tkwargs)])\n",
    "    \n",
    "    def evaluate(X):        \n",
    "    \n",
    "        output = ZDT2base(X)\n",
    "        \n",
    "        # for 1 constraint, take c1.unsqueeze(dim=-1)\n",
    "        # for >1 constraint, take torch.stack([c1, c2....], dim=-1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "from botorch.test_functions.multi_objective import ZDT3\n",
    "\n",
    "ZDT3base = ZDT3(dim=dimensions, negate=True).to(**tkwargs)\n",
    "\n",
    "class Problem_ZDT3(torch.nn.Module):\n",
    "    n_var = dimensions\n",
    "    n_obj = 2\n",
    "    n_constr = 1 # inequality constraints only!\n",
    "        \n",
    "    bounds = torch.vstack([torch.zeros(dimensions, **tkwargs),torch.ones(dimensions, **tkwargs)])\n",
    "    \n",
    "    def evaluate(X):        \n",
    "    \n",
    "        output = ZDT3base(X)\n",
    "        \n",
    "        # for 1 constraint, take c1.unsqueeze(dim=-1)\n",
    "        # for >1 constraint, take torch.stack([c1, c2....], dim=-1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "from botorch.test_functions.multi_objective import MW7\n",
    "\n",
    "MW7base = MW7(dim=dimensions, negate=True).to(**tkwargs)\n",
    "\n",
    "class Problem_MW7(torch.nn.Module):\n",
    "    n_var = dimensions\n",
    "    n_obj = 2\n",
    "    n_constr = 1\n",
    "    \n",
    "    bounds = MW7base.bounds    \n",
    "    \n",
    "    def evaluate(X):       \n",
    "        output = MW7base(X)\n",
    "        slack = -MW7base.evaluate_slack(X)\n",
    "       \n",
    "        return output, slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae740be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = torch.tensor([11,11], **tkwargs)\n",
    "\n",
    "N_TRIALS = 10\n",
    "verbose = True\n",
    "noise = 0.00\n",
    "\n",
    "hvs_qnehvi_all0 = []\n",
    "hvs_qnehvi_all1 = []\n",
    "hvs_qnehvi_all2 = []\n",
    "\n",
    "hvs_nsga3_all0 = []\n",
    "hvs_nsga3_all1 = []\n",
    "hvs_nsga3_all2 = []\n",
    "hvs_nsga3_all3 = []\n",
    "\n",
    "train_qnehvi_all = []\n",
    "train_nsga3_all = []\n",
    "\n",
    "problem = Problem_ZDT1\n",
    "\n",
    "# main loop for each trial/run, random_state will be trial number\n",
    "for trial in range(1, 10 + 1):\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} for problem {problem} with d = {dimensions}\\n\", end=\"\")\n",
    "\n",
    "    # initialize with a 2*(d+1) sample set\n",
    "\n",
    "    initial_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=2*(problem.n_var+1), seed=trial).squeeze(0)\n",
    "\n",
    "    ###############    \n",
    "    \n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=96, BATCH_SIZE=2,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all0.append(hvs_qnehvi)\n",
    "        \n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=48, BATCH_SIZE=4,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all1.append(hvs_qnehvi)\n",
    "\n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=24, BATCH_SIZE=8,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all2.append(hvs_qnehvi)\n",
    "    train_qnehvi_all.append(train_qnehvi)\n",
    "    \n",
    "    ###############    \n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=96, pop_size=2, ref_num=2,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all0.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=48, pop_size=4, ref_num=4,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all1.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=24, pop_size=8, ref_num=8,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all2.append(hvs_nsga3) \n",
    "    train_nsga3_all.append(train_nsga3)\n",
    "\n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=12, pop_size=16, ref_num=16,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all3.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "savetxt(\"ZDT1_hvs_qnehvi_96by2.csv\", hvs_qnehvi_all0, delimiter=',')\n",
    "savetxt(\"ZDT1_hvs_qnehvi_48by4.csv\", hvs_qnehvi_all1, delimiter=',')\n",
    "savetxt(\"ZDT1_hvs_qnehvi_24by8.csv\", hvs_qnehvi_all2, delimiter=',')    \n",
    "\n",
    "savetxt(\"ZDT1_hvs_nsga3_96by2.csv\", hvs_nsga3_all0, delimiter=',')\n",
    "savetxt(\"ZDT1_hvs_nsga3_48by4.csv\", hvs_nsga3_all1, delimiter=',')\n",
    "savetxt(\"ZDT1_hvs_nsga3_24by8.csv\", hvs_nsga3_all2, delimiter=',')\n",
    "savetxt(\"ZDT1_hvs_nsga3_12by16.csv\", hvs_nsga3_all3, delimiter=',')\n",
    "\n",
    "savetxt(\"ZDT1_train_qnehvi_24by8.csv\", np.array(train_qnehvi_all).reshape(-1), delimiter=',')\n",
    "savetxt(\"ZDT1_train_nsga3_24by8.csv\", np.array(train_nsga3_all).reshape(-1), delimiter=',')\n",
    "    \n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = torch.tensor([11,11], **tkwargs)\n",
    "\n",
    "N_TRIALS = 10\n",
    "verbose = True\n",
    "noise = 0.00\n",
    "\n",
    "hvs_qnehvi_all0 = []\n",
    "hvs_qnehvi_all1 = []\n",
    "hvs_qnehvi_all2 = []\n",
    "\n",
    "hvs_nsga3_all0 = []\n",
    "hvs_nsga3_all1 = []\n",
    "hvs_nsga3_all2 = []\n",
    "hvs_nsga3_all3 = []\n",
    "\n",
    "train_qnehvi_all = []\n",
    "train_nsga3_all = []\n",
    "\n",
    "problem = Problem_ZDT2\n",
    "\n",
    "# main loop for each trial/run, random_state will be trial number\n",
    "for trial in range(1, 10 + 1):\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} for problem {problem} with d = {dimensions}\\n\", end=\"\")\n",
    "\n",
    "    # initialize with a 2*(d+1) sample set\n",
    "\n",
    "    initial_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=2*(problem.n_var+1), seed=trial).squeeze(0)\n",
    "\n",
    "    ###############    \n",
    "    \n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=96, BATCH_SIZE=2,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all0.append(hvs_qnehvi)\n",
    "        \n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=48, BATCH_SIZE=4,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all1.append(hvs_qnehvi)\n",
    "\n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=24, BATCH_SIZE=8,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all2.append(hvs_qnehvi)\n",
    "    train_qnehvi_all.append(train_qnehvi)\n",
    "   \n",
    "    ###############    \n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=96, pop_size=2, ref_num=2,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all0.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=48, pop_size=4, ref_num=4,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all1.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=24, pop_size=8, ref_num=8,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all2.append(hvs_nsga3)\n",
    "    train_nsga3_all.append(train_nsga3)\n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=12, pop_size=16, ref_num=16,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all3.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "savetxt(\"ZDT2_hvs_qnehvi_96by2.csv\", hvs_qnehvi_all0, delimiter=',')\n",
    "savetxt(\"ZDT2_hvs_qnehvi_48by4.csv\", hvs_qnehvi_all1, delimiter=',')\n",
    "savetxt(\"ZDT2_hvs_qnehvi_24by8.csv\", hvs_qnehvi_all2, delimiter=',')    \n",
    "\n",
    "savetxt(\"ZDT2_hvs_nsga3_96by2.csv\", hvs_nsga3_all0, delimiter=',')\n",
    "savetxt(\"ZDT2_hvs_nsga3_48by4.csv\", hvs_nsga3_all1, delimiter=',')\n",
    "savetxt(\"ZDT2_hvs_nsga3_24by8.csv\", hvs_nsga3_all2, delimiter=',')\n",
    "savetxt(\"ZDT2_hvs_nsga3_12by16.csv\", hvs_nsga3_all3, delimiter=',')\n",
    "\n",
    "savetxt(\"ZDT2_train_qnehvi_24by8.csv\", np.array(train_qnehvi_all).reshape(-1), delimiter=',')\n",
    "savetxt(\"ZDT2_train_nsga3_24by8.csv\", np.array(train_nsga3_all).reshape(-1), delimiter=',')\n",
    "    \n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = torch.tensor([11,11], **tkwargs)\n",
    "\n",
    "N_TRIALS = 10\n",
    "verbose = True\n",
    "noise = 0.00\n",
    "\n",
    "hvs_qnehvi_all0 = []\n",
    "hvs_qnehvi_all1 = []\n",
    "hvs_qnehvi_all2 = []\n",
    "\n",
    "hvs_nsga3_all0 = []\n",
    "hvs_nsga3_all1 = []\n",
    "hvs_nsga3_all2 = []\n",
    "hvs_nsga3_all3 = []\n",
    "\n",
    "train_qnehvi_all = []\n",
    "train_nsga3_all = []\n",
    "\n",
    "problem = Problem_ZDT3\n",
    "\n",
    "# main loop for each trial/run, random_state will be trial number\n",
    "for trial in range(1, 10 + 1):\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} for problem {problem} with d = {dimensions}\\n\", end=\"\")\n",
    "\n",
    "    # initialize with a 2*(d+1) sample set\n",
    "\n",
    "    initial_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=2*(problem.n_var+1), seed=trial).squeeze(0)\n",
    "\n",
    "    ###############    \n",
    "    \n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=96, BATCH_SIZE=2,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all0.append(hvs_qnehvi)\n",
    "        \n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=48, BATCH_SIZE=4,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all1.append(hvs_qnehvi)\n",
    "\n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi_noconstr(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=24, BATCH_SIZE=8,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all2.append(hvs_qnehvi)\n",
    "    train_qnehvi_all.append(train_qnehvi)\n",
    "    \n",
    "    ###############    \n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=96, pop_size=2, ref_num=2,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all0.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=48, pop_size=4, ref_num=4,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all1.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=24, pop_size=8, ref_num=8,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all2.append(hvs_nsga3)\n",
    "    train_nsga3_all.append(train_nsga3)\n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3_noconstr(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=12, pop_size=16, ref_num=16,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all3.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "savetxt(\"ZDT3_hvs_qnehvi_96by2.csv\", hvs_qnehvi_all0, delimiter=',')\n",
    "savetxt(\"ZDT3_hvs_qnehvi_48by4.csv\", hvs_qnehvi_all1, delimiter=',')\n",
    "savetxt(\"ZDT3_hvs_qnehvi_24by8.csv\", hvs_qnehvi_all2, delimiter=',')    \n",
    "\n",
    "savetxt(\"ZDT3_hvs_nsga3_96by2.csv\", hvs_nsga3_all0, delimiter=',')\n",
    "savetxt(\"ZDT3_hvs_nsga3_48by4.csv\", hvs_nsga3_all1, delimiter=',')\n",
    "savetxt(\"ZDT3_hvs_nsga3_24by8.csv\", hvs_nsga3_all2, delimiter=',')\n",
    "savetxt(\"ZDT3_hvs_nsga3_12by16.csv\", hvs_nsga3_all3, delimiter=',')\n",
    "\n",
    "savetxt(\"ZDT3_train_qnehvi_24by8.csv\", np.array(train_qnehvi_all).reshape(-1), delimiter=',')\n",
    "savetxt(\"ZDT3_train_nsga3_24by8.csv\", np.array(train_nsga3_all).reshape(-1), delimiter=',')\n",
    "    \n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = torch.tensor([11,11], **tkwargs)\n",
    "\n",
    "N_TRIALS = 10\n",
    "verbose = True\n",
    "noise = 0.00\n",
    "\n",
    "hvs_qnehvi_all0 = []\n",
    "hvs_qnehvi_all1 = []\n",
    "hvs_qnehvi_all2 = []\n",
    "\n",
    "hvs_nsga3_all0 = []\n",
    "hvs_nsga3_all1 = []\n",
    "hvs_nsga3_all2 = []\n",
    "hvs_nsga3_all3 = []\n",
    "\n",
    "train_qnehvi_all = []\n",
    "train_nsga3_all = []\n",
    "\n",
    "problem = Problem_MW7\n",
    "\n",
    "# main loop for each trial/run, random_state will be trial number\n",
    "for trial in range(1, 10 + 1):\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} for problem {problem} with d = {dimensions}\\n\", end=\"\")\n",
    "\n",
    "    # initialize with a 2*(d+1) sample set\n",
    "\n",
    "    initial_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=2*(problem.n_var+1), seed=trial).squeeze(0)\n",
    "\n",
    "    ###############    \n",
    "    \n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=96, BATCH_SIZE=2,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all0.append(hvs_qnehvi)\n",
    "        \n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=48, BATCH_SIZE=4,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all1.append(hvs_qnehvi)\n",
    "\n",
    "    ###############    \n",
    "\n",
    "    hvs_qnehvi, train_qnehvi = optimize_qnehvi(problem, ref_point, initial_x,\n",
    "                                                        N_BATCH=24, BATCH_SIZE=8,\n",
    "                                                        random_state=trial, noise=noise, verbose=verbose)\n",
    "    hvs_qnehvi_all2.append(hvs_qnehvi)\n",
    "    train_qnehvi_all.append(train_qnehvi)\n",
    "    \n",
    "    ###############    \n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=96, pop_size=2, ref_num=2,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all0.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=48, pop_size=4, ref_num=4,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all1.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=24, pop_size=8, ref_num=8,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all2.append(hvs_nsga3)\n",
    "    train_nsga3_all.append(train_nsga3)\n",
    "    \n",
    "    ###############\n",
    "    \n",
    "    hvs_nsga3, train_nsga3 = optimize_nsga3(problem, ref_point, initial_x,\n",
    "                                                     N_BATCH=12, pop_size=16, ref_num=16,\n",
    "                                                     random_state=trial, noise=noise, verbose=False)\n",
    "    hvs_nsga3_all3.append(hvs_nsga3) \n",
    "    \n",
    "    ###############\n",
    "\n",
    "savetxt(\"MW7_hvs_qnehvi_96by2.csv\", hvs_qnehvi_all0, delimiter=',')\n",
    "savetxt(\"MW7_hvs_qnehvi_48by4.csv\", hvs_qnehvi_all1, delimiter=',')\n",
    "savetxt(\"MW7_hvs_qnehvi_24by8.csv\", hvs_qnehvi_all2, delimiter=',')    \n",
    "\n",
    "savetxt(\"MW7_hvs_nsga3_96by2.csv\", hvs_nsga3_all0, delimiter=',')\n",
    "savetxt(\"MW7_hvs_nsga3_48by4.csv\", hvs_nsga3_all1, delimiter=',')\n",
    "savetxt(\"MW7_hvs_nsga3_24by8.csv\", hvs_nsga3_all2, delimiter=',')\n",
    "savetxt(\"MW7_hvs_nsga3_12by16.csv\", hvs_nsga3_all3, delimiter=',')\n",
    "\n",
    "savetxt(\"MW7_train_qnehvi_24by8.csv\", np.array(train_qnehvi_all).reshape(-1), delimiter=',')\n",
    "savetxt(\"MW7_train_nsga3_24by8.csv\", np.array(train_nsga3_all).reshape(-1), delimiter=',')\n",
    "    \n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8ec84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
