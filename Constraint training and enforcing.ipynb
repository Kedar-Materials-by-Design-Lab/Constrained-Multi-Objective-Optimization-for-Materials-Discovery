{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T09:36:52.260262Z",
     "start_time": "2021-07-13T09:36:51.726467Z"
    }
   },
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "from pyDOE import *\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "###########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.models.gp_regression_mixed import MixedSingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list, optimize_acqf_mixed\n",
    "from botorch.acquisition.fixed_feature import FixedFeatureAcquisitionFunction\n",
    "from botorch.acquisition.objective import GenericMCObjective, ConstrainedMCObjective\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# rest of the training loop\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "# Sam's work on ref point inferrence & feasibility weighing\n",
    "from botorch.utils.multi_objective.hypervolume import infer_reference_point\n",
    "from botorch.acquisition.multi_objective.objective import MCMultiOutputObjective\n",
    "from botorch.acquisition.utils import get_infeasible_cost\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.utils import apply_constraints\n",
    "\n",
    "# argument for adding feasiility weighting to outcomes\n",
    "class GenericMCMultiOutputObjective(GenericMCObjective, MCMultiOutputObjective):\n",
    "    pass\n",
    "\n",
    "# others\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "###########\n",
    "\n",
    "# pymoo dependencies\n",
    "import pymoo\n",
    "\n",
    "from pymoo.factory import get_problem\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.algorithms.moo.unsga3 import UNSGA3\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation, get_reference_directions, get_termination\n",
    "from pymoo.operators.mixed_variable_operator import MixedVariableSampling, MixedVariableMutation, MixedVariableCrossover\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from pymoo.interface import sample\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "###########\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this is for the colorbar, you can change the cmap if you prefer other colour schemes\n",
    "from matplotlib.cm import ScalarMappable\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "\n",
    "# function to return the std dev across runs\n",
    "def ci(y, N_TRIALS):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_sobol(problem, ref_point, N_BATCH, initial_x,\n",
    "                   BATCH_SIZE=2,NUM_RESTARTS=20,RAW_SAMPLES=1024,\n",
    "                   random_state=torch.randint(1000000, (1,)).item(), verbose=False):\n",
    "    \n",
    "    print(\"Optimizing with Sobol\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # some initializing \n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # original location for an extra HV check wrt to initial samples\n",
    "    \n",
    "    ##########\n",
    "\n",
    "    # training loop for N_BATCH iterations\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        t3 = time.time()\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        # get new random observations for sobol\n",
    "        new_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=BATCH_SIZE, seed=torch.randint(1000000, (1,)).item()).squeeze(0)\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        \n",
    "        # calculate hypervolume based on checks, done on noiseless train_obj and train_con\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "\n",
    "        hvs.append(volume)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "\n",
    "        ########## end of iteration loop\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # propose feasible candidates\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(0,int((train_con.size(dim=0)))):\n",
    "        is_feas_candidate = (train_con[i,...] <= 0).all(dim=-1)  # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj_candidate = train_obj[is_feas_candidate] # take only points that fit the 1st check\n",
    "        if feas_train_obj_candidate.shape[0] > 0:  \n",
    "            candidates.append(torch.hstack((train_x[i,...], train_obj[i,...])).cpu().numpy())\n",
    "\n",
    "    print(\"DONE!\\n\")\n",
    "        \n",
    "    # returns the HV score across iterations, total training set as an array, plus list of feasible candidates\n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy(), candidates\n",
    "\n",
    "def optimize_qnehvi(problem, ref_point, N_BATCH, initial_x, # must haves\n",
    "                    BATCH_SIZE=2, custom_batch=None, # you can pick between standard batching or custom tapered\n",
    "                    feas_weighing=False, eta_relax=False, temp=0.001, # options for weighting, and constraint relaxation\n",
    "                    NUM_RESTARTS=20,RAW_SAMPLES=1024,\n",
    "                    random_state=torch.randint(1000000, (1,)).item(), noise=0, verbose=False): # change noise here!\n",
    "    \n",
    "    print(\"Optimizing with qNEHVI\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # some initializing \n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "    train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # normalize inputs to [0,1] first before feeding into model\n",
    "    standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "    standard_bounds[1] = 1\n",
    "    train_x_gp = normalize(train_x, standard_bounds)\n",
    "    \n",
    "    # form the output train_y data by concentenating ground truth train_obj with its feasibility value on the rightmost\n",
    "    # this is necessary since the surrogate GpyTorch model needs to model BOTH obj and con for predicted candidates\n",
    "    train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "    # define and train surrogate models for objective and constraint\n",
    "    model = SingleTaskGP(train_x_gp, train_y)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # original location for an extra HV check wrt to initial samples\n",
    "    \n",
    "    ########## ########## ########## start of iteration loop\n",
    "    \n",
    "    def create_idxr(i):\n",
    "        def idxr(Z):\n",
    "            return Z[..., i]\n",
    "\n",
    "        return idxr\n",
    "\n",
    "    def create_idxrs():\n",
    "        return [create_idxr(i=i) for i in range(problem.n_obj, problem.n_obj+problem.n_constr)]\n",
    "\n",
    "    # training loop for N_BATCH iterations\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        t3 = time.time()\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # fit the surrogate model\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # option for relaxation of constraint sigmoid approximation\n",
    "        \n",
    "        if eta_relax is True:\n",
    "        # value of eta for applying constraints via sigmoid approximation\n",
    "        # starts as eta=1 (closely approximates constraints) and slowly relaxes to 0.001\n",
    "            assert len(relax_list) == N_BATCH, \"Relaxation values should match no of iterations\"\n",
    "            eta = relax_list[iteration-1]\n",
    "        else:\n",
    "            eta = temp\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # option for changing from EIC to feasibility weighted outcomes\n",
    "        if feas_weighing is True:\n",
    "                        \n",
    "            # arguments for defining a feasibility weighted objective wrt to the problem\n",
    "            infeasible_cost = get_infeasible_cost(X=train_x,\n",
    "                                                  model=model,\n",
    "                                                  objective=lambda y: y[..., :problem.n_obj])\n",
    "\n",
    "            # func to define the weighted objectives on BoTorch's objective class\n",
    "            def apply_feasibility_weights(Y: Tensor, X: Optional[Tensor] = None) -> Tensor:\n",
    "                return apply_constraints(obj=Y[..., :problem.n_obj],\n",
    "                                         constraints=create_idxrs(),\n",
    "                                         samples=Y,\n",
    "                                         infeasible_cost=infeasible_cost)\n",
    "            objective = GenericMCMultiOutputObjective(apply_feasibility_weights)\n",
    "            \n",
    "            # define the acqusition function\n",
    "            acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "                model=model,\n",
    "                ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "                X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "                sampler=SobolQMCNormalSampler(num_samples=128), # determines how candidates are randomly proposed before selection\n",
    "                objective=objective,\n",
    "                prune_baseline=True, cache_pending=True) # options for improving qNEHVI, keep these on\n",
    "            \n",
    "        else:\n",
    "            # define the acqusition function for EIC if feas_weighting is false\n",
    "            acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "                model=model,\n",
    "                ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "                X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "                sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "                objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "                constraints=create_idxrs(), # constraint on last n_constr col\n",
    "                eta=eta,\n",
    "                prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # option for tapering BATCH_SIZE\n",
    "        if custom_batch is not None:\n",
    "            curr_batch_size = batch_list[iteration-1]\n",
    "            \n",
    "        else:\n",
    "            curr_batch_size = BATCH_SIZE # otherwise takes the BATCH_SIZE argument\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # propose candidates given defined qNEHVI acq func given model and latest observed training data\n",
    "        new_x, _ = optimize_acqf(\n",
    "                        acq_function=acq_func,\n",
    "                        bounds=standard_bounds, # since train_x was normalized\n",
    "                        q=curr_batch_size, # no of candidates to propose in parallel\n",
    "                        num_restarts=NUM_RESTARTS, # no of restarts if q candidates fail to show improvement\n",
    "                        raw_samples=RAW_SAMPLES,  # pool of samples to choose the starting points from\n",
    "                        options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                        equality_constraints=problem.equality_constr, # seperate argument for equality constraints, not verified yet   \n",
    "                        )\n",
    "\n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "\n",
    "        # feed new proposed observations into objective func to get its new ground truth\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "        # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "        new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "        new_con_noisy = new_con + noise*torch.randn_like(new_con)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "        train_con_noisy = torch.cat([train_con_noisy, new_con_noisy])\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # computing HV of current candidate list\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "        \n",
    "        hvs.append(volume)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        # update the surrogate models for next iteration\n",
    "        train_x_gp = normalize(train_x, standard_bounds) # dont forget to renormalize!\n",
    "        train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "        model = SingleTaskGP(train_x_gp, train_y)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "        \n",
    "        ########## ########## ########## end of iteration loop\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")   \n",
    "        \n",
    "    ##########\n",
    "    \n",
    "    # propose feasible candidates\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(0,int((train_con.size(dim=0)))):\n",
    "        is_feas_candidate = (train_con[i,...] <= 0).all(dim=-1)  # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj_candidate = train_obj[is_feas_candidate] # take only points that fit the 1st check\n",
    "        if feas_train_obj_candidate.shape[0] > 0:\n",
    "            candidates.append(torch.hstack((train_x[i,...], train_obj[i,...])).cpu().numpy())\n",
    "\n",
    "    print(\"DONE!\\n\")\n",
    "    \n",
    "    # returns the HV score across iterations, total training set as an array, plus list of feasible candidates\n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy(), candidates\n",
    "\n",
    "def optimize_nsga3(problem, ref_point, N_BATCH, initial_x, # must haves\n",
    "                   pop_size=100, ref_num=10, # as a rule of thumb, pop_size>ref_num,\n",
    "                   noise=0, random_state=np.random.randint(0, 1000000, (1,)).item(), verbose=False):\n",
    "    \n",
    "    print(\"Optimizing with UNSGA-III\")\n",
    "    \n",
    "    t0 = time.time()    \n",
    "    \n",
    "    # some initializing\n",
    "    hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    noise=noise\n",
    "\n",
    "    # define a pymoo problem class based on the torch class\n",
    "    class PymooProblem(ElementwiseProblem):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__(n_var=problem.n_var,\n",
    "                             n_obj=problem.n_obj,\n",
    "                             n_constr=problem.n_constr,\n",
    "                             xl=problem.bounds[0].cpu().numpy(),\n",
    "                             xu=problem.bounds[1].cpu().numpy())\n",
    "\n",
    "        def _evaluate(self, X, out, *args, **kwargs):\n",
    "            # base input/output from torch class\n",
    "            train_x = torch.tensor(X.tolist(), **tkwargs).unsqueeze(dim=0)\n",
    "            \n",
    "            # take the noisy observations for algo\n",
    "            train_obj, train_con = problem.evaluate(train_x)\n",
    "            train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "            train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "\n",
    "            # output the noisy observations instead\n",
    "            out[\"F\"] = -train_obj_noisy.cpu().numpy() # flip since botorch assumes maximisation vs pymoo minimization\n",
    "            out[\"G\"] = train_con_noisy.cpu().numpy()\n",
    "            \n",
    "    ##########        \n",
    "\n",
    "    pymooproblem = PymooProblem()\n",
    "\n",
    "    # create the reference directions to be used for the optimization\n",
    "    ref_dirs = get_reference_directions(\"energy\", problem.n_obj, ref_num, seed=random_state)\n",
    "    \n",
    "    # initial sampling\n",
    "    sampling = initial_x.cpu().numpy()\n",
    "    \n",
    "    # create the algorithm object\n",
    "    algorithm = UNSGA3(pop_size=pop_size,\n",
    "                      ref_dirs=ref_dirs,\n",
    "                      sampling=sampling\n",
    "                     )\n",
    "\n",
    "    # execute the optimization, take N_BATCH+1 since 1st iteration is just the initial sampling\n",
    "    res = minimize(pymooproblem, algorithm, seed=random_state, termination=('n_gen', N_BATCH+1),\n",
    "                   verbose=verbose, save_history=True)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")\n",
    "\n",
    "    ##########\n",
    "        \n",
    "    # calculate hypervolume based on checks, done on noiseless train_obj and train_con\n",
    "    for i in range(0,N_BATCH):\n",
    "        train_x = torch.tensor(res.history[i].pop.get(\"X\").tolist(), **tkwargs)\n",
    "        train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "        \n",
    "        hvs.append(volume)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # convert population data into tensor form\n",
    "    # initial data\n",
    "    train_x = torch.tensor(res.history[0].pop.get(\"X\").tolist(), **tkwargs)\n",
    "    train_obj, train_con = problem.evaluate(train_x) \n",
    "    # population at each iteration\n",
    "    for i in range(1,N_BATCH+1): # don't forget we did +1 for total iterations\n",
    "        new_x = torch.tensor(res.history[i].pop.get(\"X\").tolist(), **tkwargs)\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        \n",
    "    ##########\n",
    "    \n",
    "    # propose feasible candidates\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(0,int((train_con.size(dim=0)))):\n",
    "        is_feas_candidate = (train_con[i,...] <= 0).all(dim=-1)  # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj_candidate = train_obj[is_feas_candidate] # take only points that fit the 1st check\n",
    "        if feas_train_obj_candidate.shape[0] > 0:\n",
    "            candidates.append(torch.hstack((train_x[i,...], train_obj[i,...])).cpu().numpy())\n",
    "\n",
    "    print(\"DONE!\\n\")\n",
    "        \n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy(), candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 8\n",
    "\n",
    "from botorch.test_functions.multi_objective import C2DTLZ2\n",
    "\n",
    "LZ2base = C2DTLZ2(dim=dimensions, num_objectives=2, negate=True).to(**tkwargs)\n",
    "\n",
    "class Problem_LZ2(torch.nn.Module):\n",
    "    n_var = dimensions\n",
    "    n_obj = 2\n",
    "    n_constr = 1\n",
    "    \n",
    "    bounds = LZ2base.bounds    \n",
    "    \n",
    "    def evaluate(X):       \n",
    "        output = LZ2base(X)\n",
    "        slack = -LZ2base.evaluate_slack(X)\n",
    "       \n",
    "        return output, slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem_LZ2\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "We assume here that the constraints are NOT black-box, but enforceable and known to user\n",
    "We proceed to randomly generate 1000 virtual samples then virtually optimize with U-NSGA-III to get our feasible sample set\n",
    "'''\n",
    "\n",
    "class PymooProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var=problem.n_var,\n",
    "                         n_obj=1,\n",
    "                         xl=problem.bounds[0].cpu().numpy(),\n",
    "                         xu=problem.bounds[1].cpu().numpy())\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # base input/output from torch class\n",
    "        train_x = torch.tensor(X.tolist(), **tkwargs).unsqueeze(dim=0)\n",
    "\n",
    "        # take the noisy observations for algo\n",
    "        train_obj, train_con = problem.evaluate(train_x)\n",
    "        for i in range(train_con.shape[0]):\n",
    "            if train_con[i]<=0:\n",
    "                train_con[i] = 0\n",
    "\n",
    "        out[\"F\"] = train_con.cpu().numpy() # flip since botorch assumes maximisation vs pymoo minimization\n",
    "\n",
    "##########        \n",
    "\n",
    "pymooproblem = PymooProblem()\n",
    "\n",
    "# create the reference directions to be used for the optimization\n",
    "ref_dirs = get_reference_directions(\"energy\", 1, 10, seed=random_state)\n",
    "\n",
    "# initial sampling\n",
    "sampling = draw_sobol_samples(bounds=problem.bounds,n=1, q=1000, seed=random_state).squeeze(0).cpu().numpy()\n",
    "\n",
    "# create the algorithm object\n",
    "algorithm = UNSGA3(pop_size=8*(problem.n_var+1),\n",
    "                  ref_dirs=ref_dirs,\n",
    "                  sampling=sampling\n",
    "                 )\n",
    "\n",
    "# execute the optimization, take N_BATCH+1 since 1st iteration is just the initial sampling\n",
    "res = minimize(pymooproblem, algorithm, seed=random_state, termination=('n_gen', 100+1),\n",
    "               verbose=False, save_history=True)\n",
    "\n",
    "'''\n",
    "The simulated feasible values are then validated to form our initial sample set\n",
    "'''\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "# don't forget to flip back negative if you done so in Problem class definition!\n",
    "initial_x = torch.tensor(res.history[-1].pop.get(\"X\"), **tkwargs)\n",
    "initial_obj, initial_con = Problem_LZ2.evaluate(initial_x)\n",
    "\n",
    "ax.scatter(-initial_obj[...,0].cpu().numpy(),\n",
    "           -initial_obj[...,1].cpu().numpy(),\n",
    "           s=15, alpha=0.8, label='Feasible Proposed Points')\n",
    "\n",
    "ax.legend(loc='lower left')\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"Constraint optimization of C2-DTLZ2 (d=8)\")\n",
    "ax.set_xlim(0, 1.1)\n",
    "ax.set_ylim(0, 1.1)\n",
    "#ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point = torch.tensor([1.1, 1.1], **tkwargs)\n",
    "noise=0\n",
    "\n",
    "torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "\n",
    "##########\n",
    "# generate initial training data for that run\n",
    "train_x = initial_x\n",
    "train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "# add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "\n",
    "##########\n",
    "\n",
    "# normalize inputs to [0,1] first before feeding into model\n",
    "standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "standard_bounds[1] = 1\n",
    "train_x_gp = normalize(train_x, standard_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "before proceeding with optimization, lets train the model to handle constraints better first\n",
    "by adding extra constraint data virtually\n",
    "'''\n",
    "\n",
    "models = []\n",
    "for i in range(train_obj_noisy.shape[-1]):\n",
    "    models.append(\n",
    "        SingleTaskGP(train_x_gp, train_obj_noisy[..., i:i+1], outcome_transform=Standardize(m=1))\n",
    "    )\n",
    "    \n",
    "con_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=1000, seed=random_state).squeeze(0)\n",
    "con_obj, con_con = problem.evaluate(con_x)\n",
    "con_con_noisy = con_con + noise*torch.randn_like(con_con)\n",
    "\n",
    "virtual_x = torch.cat([train_x, con_x])\n",
    "virtual_x_gp = normalize(virtual_x, standard_bounds)\n",
    "virtual_con = torch.cat([train_con_noisy, con_con_noisy])\n",
    "    \n",
    "for i in range(virtual_con.shape[-1]):\n",
    "    models.append(\n",
    "        SingleTaskGP(virtual_x_gp, virtual_con[..., i:i+1], outcome_transform=Standardize(m=1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelListGP(*models)\n",
    "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "def create_idxr(i):\n",
    "    def idxr(Z):\n",
    "        return Z[..., i]\n",
    "\n",
    "    return idxr\n",
    "\n",
    "def create_idxrs():\n",
    "    return [create_idxr(i=i) for i in range(problem.n_obj, problem.n_obj+problem.n_constr)]\n",
    "\n",
    "# fit the surrogate model\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "##########\n",
    "\n",
    "acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "    model=model,\n",
    "    ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "    X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "    sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "    objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "    constraints=create_idxrs(), # constraint on last n_constr col\n",
    "    eta=0.001, # enforce very high temperature here\n",
    "    prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 8 samples, only 2 were feasible.\n",
      "6 more sample(s) required.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "let's do the first run of qNEHVI here, and see how many feasible samples we get\n",
    "Here we check for feasibility, enforcing an epsilon/error margin of 0.005\n",
    "\n",
    "'''\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# propose candidates given defined qNEHVI acq func given model and latest observed training data\n",
    "new_x, _ = optimize_acqf(\n",
    "                acq_function=acq_func,\n",
    "                bounds=standard_bounds, # since train_x was normalized\n",
    "                q=BATCH_SIZE, # no of candidates to propose in parallel\n",
    "                num_restarts=20, # no of restarts if q candidates fail to show improvement\n",
    "                raw_samples=1024,  # pool of samples to choose the starting points from\n",
    "                options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                )\n",
    "\n",
    "# unormalize our training inputs back to original problem bounds\n",
    "new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "feas_num = new_con[(new_con<=0.005).all(dim=-1)].shape[0]\n",
    "\n",
    "print(f\"Out of {BATCH_SIZE} samples, only {feas_num} were feasible.\")\n",
    "print(f\"{BATCH_SIZE - feas_num} more sample(s) required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Only 5 candidates were feasible, this becomes a conundrum: How would we then batch sample evenly?\n",
    "We could consider having 2 surrogate models:\n",
    "1. The primary model (BoTorch GP) which drives qNEHVI acquisition function\n",
    "2. The secondary model that kicks in when we need to get more samples\n",
    "\n",
    "Both surrogates are trained from the same initial sample set,\n",
    "but the secondary model kicks in to provide low-fidelity virtual samples to drive qNEHVI to 'make up' for missing samples\n",
    "Afterwards, both models are properly trained on the full batch that is validated\n",
    "\n",
    "To train the secondary model: we can directly port over input x and constraint con,\n",
    "objective obj will be taken from primary GP\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_pred = model(new_x[(new_con<=0.005).all(dim=-1)]).sample()\n",
    "virtual_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_pred[...,:problem.n_obj,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_pred[:problem.n_obj].reshape(virtual_pred[:problem.n_obj].shape[0], virtual_pred[:problem.n_obj].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_x = torch.cat([train_x, new_x[(new_con<=0.005).all(dim=-1)]])\n",
    "virtual_obj = torch.cat([train_obj, new_obj[(new_con<=0.005).all(dim=-1)]])\n",
    "\n",
    "\n",
    "\n",
    "virtual_con = torch.cat([train_con, new_con[(new_con<=0.005).all(dim=-1)]])\n",
    "\n",
    "\n",
    "\n",
    "# define and train surrogate models for objective and constraint\n",
    "model_virtual = SingleTaskGP(train_x_gp, train_y)\n",
    "mll_virtual = ExactMarginalLogLikelihood(model.likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rand = torch.rand((BATCH_SIZE - feas_num, problem.n_var), **tkwargs)\n",
    "new_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate(new_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Only 5 candidates were feasible, this becomes a conundrum: How would we then batch sample evenly?\n",
    "We could consider having 2 surrogate models:\n",
    "1. The primary model (BoTorch GP) which drives qNEHVI acquisition function\n",
    "2. The secondary model that kicks in when we need to get more samples\n",
    "\n",
    "Both surrogates are trained from the same initial sample set,\n",
    "but the secondary model kicks in to provide low-fidelity virtual samples to drive qNEHVI to 'make up' for missing samples\n",
    "Afterwards, both models are properly trained on the full batch that is validated\n",
    "\n",
    "To train the secondary model: we can directly port over input x and constraint con,\n",
    "but objective obj doesn't exist yet, we need to find a way to simulate this\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ##########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "    new_con_noisy = new_con + noise*torch.randn_like(new_con)\n",
    "\n",
    "    # update training points by concatenating the new values into their respective tensors\n",
    "    train_x = torch.cat([train_x, new_x])\n",
    "    train_obj = torch.cat([train_obj, new_obj])\n",
    "    train_con = torch.cat([train_con, new_con])\n",
    "    train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "    train_con_noisy = torch.cat([train_con_noisy, new_con_noisy])\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # computing HV of current candidate list\n",
    "    is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "    feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "    if feas_train_obj.shape[0] > 0:\n",
    "        pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "        pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "        volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "    else:\n",
    "        volume = 0.0\n",
    "\n",
    "    hvs.append(volume)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # update the surrogate models for next iteration\n",
    "    train_x_gp = normalize(train_x, standard_bounds) # dont forget to renormalize!\n",
    "    train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "    model = SingleTaskGP(train_x_gp, train_y)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    t4 = time.time()\n",
    "    if verbose:\n",
    "        print(\n",
    "                f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                f\"{hvs[-1]:>4.2f}, \"\n",
    "                f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                , end=\"\")\n",
    "\n",
    "    ########## ########## ########## end of iteration loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Latin Hypercube Samping",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.433px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
