{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "###########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.models.gp_regression_mixed import MixedSingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list, optimize_acqf_mixed\n",
    "from botorch.acquisition.fixed_feature import FixedFeatureAcquisitionFunction\n",
    "from botorch.acquisition.objective import GenericMCObjective, ConstrainedMCObjective\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# rest of the training loop\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "# Sam's work on ref point inferrence & feasibility weighing\n",
    "from botorch.utils.multi_objective.hypervolume import infer_reference_point\n",
    "from botorch.acquisition.multi_objective.objective import MCMultiOutputObjective\n",
    "from botorch.acquisition.utils import get_infeasible_cost\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.utils import apply_constraints\n",
    "\n",
    "# argument for adding feasiility weighting to outcomes\n",
    "class GenericMCMultiOutputObjective(GenericMCObjective, MCMultiOutputObjective):\n",
    "    pass\n",
    "\n",
    "# others\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce785164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n",
      "Numpy 1.20.1\n",
      "Pandas 1.2.4\n",
      "PyTorch 1.10.0\n",
      "BoTorch 0.5.1\n",
      "\n",
      "Cuda device NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "print('Numpy '+np.__version__)\n",
    "print('Pandas '+pd.__version__)\n",
    "print('PyTorch '+torch.__version__)\n",
    "print('BoTorch '+botorch.__version__)\n",
    "\n",
    "print('\\nCuda device {}'.format(torch.cuda.get_device_name(torch.cuda.current_device())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ae4999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1 (g/L)</th>\n",
       "      <th>S2 (g/L)</th>\n",
       "      <th>S3 (g/L)</th>\n",
       "      <th>P1 (g/L)</th>\n",
       "      <th>T1 (g/L)</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>Viscosity (mPas)</th>\n",
       "      <th>Price ($/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.60</td>\n",
       "      <td>13.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>27.75</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.103561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.57</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>19.84</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.098841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6100</td>\n",
       "      <td>1.31</td>\n",
       "      <td>13.08</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.3600</td>\n",
       "      <td>292.37</td>\n",
       "      <td>573.87</td>\n",
       "      <td>0.119770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.35</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>32.23</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.097497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0038</td>\n",
       "      <td>5.21</td>\n",
       "      <td>9.79</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>43.61</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.096209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>8.1300</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>34.12</td>\n",
       "      <td>510.04</td>\n",
       "      <td>0.163156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.8500</td>\n",
       "      <td>3.52</td>\n",
       "      <td>9.64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>19.62</td>\n",
       "      <td>528.88</td>\n",
       "      <td>0.120082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5.3700</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.07</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.9600</td>\n",
       "      <td>22.13</td>\n",
       "      <td>3449.00</td>\n",
       "      <td>0.153990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.4800</td>\n",
       "      <td>6.82</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>469.36</td>\n",
       "      <td>2427.21</td>\n",
       "      <td>0.114223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3.0600</td>\n",
       "      <td>4.91</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>20.89</td>\n",
       "      <td>222.30</td>\n",
       "      <td>0.125421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S1 (g/L)  S2 (g/L)  S3 (g/L)  P1 (g/L)  T1 (g/L)  Turbidity (NTU)  \\\n",
       "0      0.4300      0.60     13.97      0.53    0.1800            27.75   \n",
       "1      0.0870      0.57     14.34      0.42    0.0200            19.84   \n",
       "2      0.6100      1.31     13.08      1.19    1.3600           292.37   \n",
       "3      0.1500      0.50     14.35      0.16    0.0850            32.23   \n",
       "4      0.0038      5.21      9.79      0.14    0.0087            43.61   \n",
       "..        ...       ...       ...       ...       ...              ...   \n",
       "123    8.1300      3.36      3.51      0.37    0.8500            34.12   \n",
       "124    1.8500      3.52      9.64      0.16    1.4200            19.62   \n",
       "125    5.3700      0.56      9.07      0.68    1.9600            22.13   \n",
       "126    0.4800      6.82      7.70      0.33    1.7000           469.36   \n",
       "127    3.0600      4.91      7.04      0.41    0.6500            20.89   \n",
       "\n",
       "     Viscosity (mPas)  Price ($/L)  \n",
       "0                6.96     0.103561  \n",
       "1                6.37     0.098841  \n",
       "2              573.87     0.119770  \n",
       "3                8.26     0.097497  \n",
       "4                8.51     0.096209  \n",
       "..                ...          ...  \n",
       "123            510.04     0.163156  \n",
       "124            528.88     0.120082  \n",
       "125           3449.00     0.153990  \n",
       "126           2427.21     0.114223  \n",
       "127            222.30     0.125421  \n",
       "\n",
       "[128 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('multiobjdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861ba857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "random_state = 1\n",
    "noise = 0\n",
    "initial_size = 16\n",
    "q = 8\n",
    "verbose = True\n",
    "\n",
    "X = df.iloc[:,0:5]\n",
    "y1 = -df['Turbidity (NTU)']\n",
    "y2 = -(df['Viscosity (mPas)'] - 3)**2\n",
    "y = pd.concat([y1, y2], axis=1)\n",
    "\n",
    "X_pool = torch.tensor(np.array(X), **tkwargs)\n",
    "y_pool = torch.tensor(np.array(y), **tkwargs)\n",
    "\n",
    "N_BATCH = (X_pool.shape[0]-initial_size)/q\n",
    "\n",
    "assert N_BATCH%1 == 0.0, \"No of initial samples, batch size and total pool size must tally\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364210e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial training data for that run\n",
    "pareto_mask = is_non_dominated(y_pool) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "pareto_y = y_pool[pareto_mask]\n",
    "ref_point = infer_reference_point(pareto_y)\n",
    "ref_point = -ref_point\n",
    "hvs = []\n",
    "hv=Hypervolume(ref_point=-ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "\n",
    "torch.manual_seed(random_state)\n",
    "perm = torch.randperm(X_pool.shape[0])\n",
    "idx = perm[:16] # takes 16 samples\n",
    "train_x = X_pool[idx]\n",
    "train_obj = y_pool[idx]\n",
    "\n",
    "x_mask = torch.ones(X_pool.shape[0], dtype=torch.bool)\n",
    "x_mask[idx] = False\n",
    "X_pool = X_pool[x_mask]\n",
    "\n",
    "y_mask = torch.ones(y_pool.shape[0], dtype=torch.bool)\n",
    "y_mask[idx] = False\n",
    "y_pool = y_pool[y_mask]\n",
    "\n",
    "models = []\n",
    "for i in range(train_obj.shape[-1]):\n",
    "    models.append(\n",
    "        SingleTaskGP(train_x, train_obj[..., i:i+1], outcome_transform=Standardize(m=1))\n",
    "    )\n",
    "    \n",
    "model = ModelListGP(*models)\n",
    "mll = SumMarginalLogLikelihood(model.likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32af4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  1 of 14: Hypervolume = 7927.67, time = 2.00s, remaining samples in pool: 104\n",
      "Batch  2 of 14: Hypervolume = 7927.67, time = 1.28s, remaining samples in pool: 96\n",
      "Batch  3 of 14: Hypervolume = 8033.07, time = 1.25s, remaining samples in pool: 88\n",
      "Batch  4 of 14: Hypervolume = 8033.07, time = 2.03s, remaining samples in pool: 80\n",
      "Batch  5 of 14: Hypervolume = 8038.00, time = 2.13s, remaining samples in pool: 72\n",
      "Batch  6 of 14: Hypervolume = 11424.14, time = 1.86s, remaining samples in pool: 64\n",
      "Batch  7 of 14: Hypervolume = 13791.47, time = 2.01s, remaining samples in pool: 56\n",
      "Batch  8 of 14: Hypervolume = 13791.47, time = 1.89s, remaining samples in pool: 48\n",
      "Batch  9 of 14: Hypervolume = 20946.85, time = 2.11s, remaining samples in pool: 40\n",
      "Batch 10 of 14: Hypervolume = 21088.15, time = 1.99s, remaining samples in pool: 32\n",
      "Batch 11 of 14: Hypervolume = 21088.15, time = 3.54s, remaining samples in pool: 24\n",
      "Batch 12 of 14: Hypervolume = 21088.15, time = 3.72s, remaining samples in pool: 16\n",
      "Batch 13 of 14: Hypervolume = 21088.15, time = 1.85s, remaining samples in pool: 8\n",
      "Batch 14 of 14: Hypervolume = 21088.15, time = 1.97s, remaining samples in pool: 0\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, int(N_BATCH)+1):\n",
    "    \n",
    "    t3 = time.time()\n",
    "\n",
    "    # fit the surrogate model\n",
    "    fit_gpytorch_model(mll)\n",
    "\n",
    "    acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=-ref_point, # for computing HV, must flip for BoTorch\n",
    "        X_baseline=train_x, # feed total list of train_x for this current iteration\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=np.arange(2).tolist()), # optimize first n_obj col \n",
    "        prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "\n",
    "    acq_value_list = []\n",
    "\n",
    "    for i in range(0, X_pool.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            acq_value = acq_func(X_pool[i].unsqueeze(dim=0))\n",
    "            acq_value_list.append(acq_value.item())\n",
    "\n",
    "    #acq_value_list.sort(reverse=True)\n",
    "    top_idx = sorted(range(len(acq_value_list)), key=lambda i: acq_value_list[i], reverse=True)[:q]\n",
    "    new_x = X_pool[top_idx]\n",
    "    new_obj = y_pool[top_idx]\n",
    "\n",
    "    # update training points by concatenating the new values into their respective tensors\n",
    "    train_x = torch.cat([train_x, new_x])\n",
    "    train_obj = torch.cat([train_obj, new_obj])\n",
    "\n",
    "    models = []\n",
    "    for i in range(train_obj.shape[-1]):\n",
    "        models.append(\n",
    "            SingleTaskGP(train_x, train_obj[..., i:i+1], outcome_transform=Standardize(m=1))\n",
    "        )\n",
    "\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    \n",
    "    x_mask = torch.ones(X_pool.shape[0], dtype=torch.bool)\n",
    "    x_mask[top_idx] = False\n",
    "    X_pool = X_pool[x_mask]\n",
    "\n",
    "    y_mask = torch.ones(y_pool.shape[0], dtype=torch.bool)\n",
    "    y_mask[top_idx] = False\n",
    "    y_pool = y_pool[x_mask]\n",
    "    \n",
    "    # computing HV of current candidate list\n",
    "    pareto_mask = is_non_dominated(train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "    pareto_y = train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "    volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "\n",
    "    hvs.append(volume)\n",
    "    \n",
    "    t4 = time.time()\n",
    "    if verbose:\n",
    "        print(\n",
    "                f\"Batch {iteration:>2} of {int(N_BATCH)}: Hypervolume = \"\n",
    "                f\"{hvs[-1]:>4.2f}, \"\n",
    "                f\"time = {t4-t3:>4.2f}s, \"\n",
    "                f\"remaining samples in pool: {y_pool.shape[0]}\\n\"\n",
    "                , end=\"\")\n",
    "                    \n",
    "print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
